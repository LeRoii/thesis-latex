% !TeX root = ../main.tex

\xchapter{结论与展望}{Conclusion and Future Work}

\xsection{结论}{Conclusion}
本文围绕“多光谱融合智能光电处理算法与系统设计”这一主题，针对无人机在低空复杂环境中对实时、鲁棒感知与跟踪的迫切需求，展开了一系列从理论方法、关键算法到工程系统的深入研究。现有目标检测跟踪算法在无人机视角下仍存在技术瓶颈，对于像素占比极小的目标，其检测精度仍有较大提升空间，对于长时被遮挡目标，现有目标跟踪算法缺乏可靠的丢失判定与重检测机制。本文通过将先进的人工智能算法与严格的嵌入式工程约束相结合，致力于解决机载平台在有限算力、内存和功耗下实现高精度环境感知的挑战，构建了一套从核心处理算法到完整软硬件系统的完整解决方案。本文主要研究成果包括以下四个方面。
\begin{enumerate}
    \item[(1)] 提出了面向可见光航拍图像的高性能小目标检测网络BAP-DETR，在无人机航拍图像的目标检测任务中，算法需应对极端尺度变化、密集小目标不均匀分布及复杂背景干扰三重挑战。通用目标检测器在此类场景下存在显著性能差距，而直接提高输入图像分辨率又会引发计算量激增，难以满足机载平台的实时性要求。现有小目标检测方法的网络架构往往在特征传递过程中丢失对小目标至关重要的细粒度信息，导致精度与速度难以兼顾。针对这些问题，本文设计了双重注意力处理模块，通过通道分离策略实现卷积与自注意力全局建模能力的并行优化与交互，使模型能从复杂场景中提取更具判别力的细微特征。其次，设计了配备频域感知融合模块的双融合编码器，该设计能有效保留并融合包含丰富细节的低层特征与承载语义信息的高层特征，显著增强了对小目标的特征保留能力与多尺度感知性能。最后，在损失函数中，结合倒数归一化Wasserstein距离与CIoU损失，在不增加推理开销的前提下，进一步提升了对小目标定位的精确度与鲁棒性。在VisDrone、UAVDT和AI-TOD三个公开航拍数据集上的实验表明，BAP-DETR在保持推理效率的同时，平均检测精度（AP）较基线模型提升6.9\%，并实现了17.5\%的计算负载降低。这项工作为无人机可见光视角下的实时高精度小目标检测提供了一个有效的解决方案，有效平衡了机载场景下对精度与速度的要求。

    \item[(2)] 设计了面向无人机红外图像的轻量化小目标检测网络MFF-DCNet，无人机红外成像在夜间、烟尘等恶劣环境下具有不可替代的优势，但其图像固有的低分辨率、低对比度、高噪声及纹理缺失特性，使得目标检测，尤其是对远距离像素占比极小的微弱目标的检测，成为极具挑战性的难题。现有通用检测模型直接迁移至红外图像时性能显著下降，而计算密集的先进网络又难以在机载边缘设备的严格算力约束下实现实时推理。针对这些问题，本文设计了深度可分离跨阶段Transformer模块用于增强主干网络的特征提取能力，该结构有效建模了远距离弱小目标与复杂背景之间的长距离上下文依赖关系，增强了特征的判别性。其次，提出了一个新颖的多特征聚焦颈部结构，通过自适应的跨尺度特征加权与融合策略，提升了网络对小目标特征的提取能力。在HIT-UAV和DroneVehicle红外航拍数据集上的实验表明，MFF-DCNet不仅检测精度（AP）显著超越专用无人机图像检测器及YOLO、DETR系列等基线模型，更在处理效率上实现了提升。同时，该网络在NVIDIA Jetson Orin NX嵌入式边缘计算平台上达到了39.6 FPS的实时处理能力，验证了其满足实际机载任务对低功耗、高实时性的要求，为无人机全天候智能感知提供了可靠的红外视觉解决方案。

    \item[(3)] 提出了一种面向边缘计算设备的抗遮挡长时目标跟踪框架SKF-Tracker，在无人机执行持续监视、目标跟踪等任务时，目标被环境中的建筑、植被等障碍物完全遮挡是导致跟踪失败的主要原因。现有主流跟踪算法及公开数据集多聚焦于短时、部分遮挡的场景，且缺乏无人机视角下的图像，导致算法在实际复杂城市场景中鲁棒性不足。针对这一问题，本文设计了一种具备目标丢失判断与重捕获能力的抗遮挡长时跟踪框架，使用结构相似性指数作为跟踪置信度判断依据，结合轨迹预测与动态搜索的重捕获机制，使系统能够在识别到目标被遮挡的情况后，及时暂停目标模板更新，在目标重现时快速锁定，同时，自适应的模板更新策略确保了模型外观记忆的可靠性。为了针对性地验证算法抗遮挡能力，本文构建了一个多模态（可见光与红外）无人机视角目标跟踪数据集MMUOT-1050，包含353段可见光视频序列与697段红外视频序列，每段视频均包含目标被完全遮挡的场景。SKF-Tracker在该数据集上实现了89.37\%的可见光视频成功率和91.93\%的红外视频成功率，与基线方法相比提升了14\%和11.73\%。在实时性方面，SKF-Tracker在保持最高精度的同时，仍能保持31.25的帧率，其速度远超基于深度神经网络的SiamRPN，并且不占用NPU资源。该工作为解决面向边缘计算设备的抗遮挡目标跟踪提供了一套兼具理论创新与工程落地的可行路径。
    
    \item[(4)] 设计并实现了一套能够满足低功耗、高实时性要求的机载智能光电原型系统，将算法创新融入到完整的工程实践中。该系统采用高性能边缘计算模组，集成了模块化的多光谱数据采集、处理与通信软件框架，并通过大疆M350 RTK无人机平台进行了实地飞行验证。在硬件层面，系统以高性能异构边缘计算模组（RK3588）为核心，集成了可见光与红外传感器，实现了多光谱数据的采集与处理。利用芯片厂商提供的专用工具链（RKNN），对网络模型进行了针对性的优化，解决了网络模型在边缘侧部署的核心瓶颈。在软件层面，本文构建了一套模块化、高内聚、低耦合的嵌入式应用软件框架。数据接入层以工厂模式管理多源异构传感器，数据处理层以策略模式封装并动态调度检测、跟踪等智能算法，通信总线层以事件驱动与消息队列实现模块间异步通信，通过无锁环形缓冲区和内存池保障了数据流的高效与确定性。同时，系统提供了支持多协议的上位机交互接口并支持算法参数高度可配置，大幅提升系统的可扩展性与工程可维护性。
\end{enumerate}

本文围绕低空无人机在复杂环境下的智能感知需求，从理论方法、核心算法、系统实现到实验验证，实现了从算法设计到工程实现与性能验证的完整闭环。所提出的BAP-DETR、MFF-DCNet及SKF-Tracker算法，针对无人机视角下的小目标检测与严重遮挡跟踪等难题提供了有效解决方案，基于软硬件协同设计的智能光电原型系统，为算法的工程化落地与性能验证提供了坚实基础。本工作不仅在提升无人机自主感知的精度、鲁棒性与实时性方面取得了进展，同时为机载智能光电系统原型设计提供了经验与参考。

\xsection{展望}{Future Work}
本文所提出的算法与系统，显著提升了机载平台在复杂环境下对特定目标的感知精度与跟踪鲁棒性，为执行明确的侦察、监视等任务提供了有效的技术支撑。然而，当前的系统能力仍集中在对环境的“感知”与“反应”层面，在结合场景上下文、任务意图进行高层语义理解与自主决策方面，与具备认知能力的智能体（Agent）仍存在本质差距。这一差距的根源，一方面在于现有嵌入式平台的硬件条件，难以承载需要大规模算力的先进模型，如开放世界目标检测、视觉-语言模型（Vision-Language Models, VLM）等，另一方面，在于现有算法多聚焦于单一任务的优化，缺乏对多任务、多模态信息的综合处理与理解能力。后续的研究将在现有基础上，面向资源受限平台与开放环境下智能感知的需求，融合边云协同与模型压缩蒸馏技术以引入具备开放世界识别与跨模态理解能力的模型，强化检测、跟踪、重识别与语义解析的协同工作，形成从低级感知到高层意图理解与策略生成的闭环，具体围绕以下几个方面展开：

\paragraph{开放世界感知与跨模态信息融合}
本文中机载光电系统部署的目标检测模型是固定类别的闭集检测模型，仅能识别在训练集中预先定义好的有限类别目标，但对未见类别与长尾目标的适配能力有限。视觉-语言模型如CLIP、GLIP及其变体，具备开放词汇感知与零样本识别能力，这类模型通过在海量图像-文本对上进行对比学习，将视觉特征与语义概念在统一的高维空间中对齐，从而能够仅根据自然语言描述来检测和识别未见过的类别，而无需针对这些类别进行任何模型参数的更新或重新训练，使系统能够识别未知类别与长尾目标，实现对未知环境的感知。后续工作将探索如何在机载环境下融入视觉-语言模型的感知能力，可从硬件升级与架构优化两个方面进行探索，NVIDIA Jetson AGX Orin/Thor等新一代边缘计算模组可提供数十至上百TOPS的AI算力，使在端侧部署轻量化视觉-语言模型成为可能，Jetson Orin Nano上可部署约3B参数的蒸馏VLM，在AGX Orin上可部署70B参数的模型，在AGX Thor上能够运行参数超过100B的模型。升级硬件是直接有效的方案，但是需要考虑机载环境下的物理约束，系统功耗，散热设计，成本与可维护性等因素，同时也要考虑整个软件框架迁移的成本。另一方面，在低算力平台上，可通过边云协同计算架构，将复杂的视觉-语言模型部署在云端服务器上，机载平台仅运行轻量级的前端感知与数据处理模块，将关键帧或特征上传至云端进行推理，云端再将结果反馈至机载平台，实现低延迟的开放世界感知能力。该方案能够利用云端强大的计算资源，同时减轻机载平台的算力负担，但需要解决网络连接的稳定性与带宽限制问题，后续研究将结合模型压缩、蒸馏与边云协同技术，探索在机载环境下实现开放世界感知的可行路径。

\paragraph{意图理解与自主策略生成}
本文实现了机载智能光电系统对目标的精准感知与稳定跟踪，但是主要聚焦于单一任务的优化，缺乏对场景高级语义与任务意图的理解能力。后续研究将探索面向动态任务场景的意图理解与自主策略生成，在目标与场景意图理解层面，发展基于多模态时序数据的目标行为建模与意图推断方法。构建一个融合目标运动状态、外观语境与场景语义的智能推理模型，通过一个通用的多模态编码器，将目标的外观、运动和历史轨迹提取为时空对齐、富含语义的统一特征表示，采用类似TAMFormer的多模态Transformer解码器，对特征进行时序建模与上下文关联，生成语义化意图标签。在任务驱动的自主策略生成层面，研究将高层意图理解转化为具体的感知与行动策略，使系统能根据任务目标、当前态势理解以及平台自身约束自主制定并动态调整传感器调度策略、平台机动建议以及信息收集优先级。同时，需要设计简单易用的人机交互接口，使自主生成的策略能够以清晰的方式呈现给操作人员，支持“人在回路”的核准、修改与控制，形成混合增强智能的闭环，确保最终决策的可靠性。

\paragraph{高性能边缘计算平台选型与工程化验证}
本文中使用的边缘计算模组只能满足于初级模型的算力需求，主要面向经过优化的卷积神经网络，在面对DETR类基于注意力机制、计算复杂度更高的先进模型时，现有边缘算力难以满足实时处理的要求。至于参数规模庞大、需要跨模态对齐的多模态视觉-语言模型，其研究与验证更是高度依赖服务器集群与特定数据集，导致在实际工程应用，尤其是在资源受限的机载平台上，其性能与均缺乏充分验证。要实现一个具备高级认知与自主决策能力的智能体，必须首先构建强大的边缘算力基础，并围绕此基础设计合理的软硬件架构。NVIDIA Jetson AGX Orin/Thor系列提供了可行的解决方案，其专用的TensorRT和vLLM服务框架，能够实现在边缘端实时运行包括视觉语言模型、视觉语言动作模型在内的大型生成式模型，平台原生支持FP8、W4A16等先进量化格式以及预测性解码等技术，能有效在模型精度、速度和内存占用之间取得平衡，为资源受限的机载平台运行复杂模型提供了可能。瑞芯微RK3588的RKLLM工具链也为在边缘设备上部署大模型提供解决方案，能够支持TinyLlama 1.1B、Qwen2.5-1.5B等参数量在十亿级别的模型，但是目前还处于原型验证阶段，局限于开发板环境，围绕固定模型和示例场景，距离工程化应用还有很大距离。此外，后续研究还应该探索构建实际工程应用场景与系统性测试验证体系，将先进算法从实验室的固定样例转变为能够在真实、动态的机载环境中稳定工作的工程产品，为机载智能光电系统提供高级认知能力。


