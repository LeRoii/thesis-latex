% !TeX root = ../main.tex


\xchapter{基于多特征聚焦与跨阶段Transformer的红外小目标检测网络}{Multi-Feature Focus and Cross-Stage Transformer Network for Infrared Small Object Detection}

在机载光电系统中，红外成像传感器是实现全天时、全天候环境感知的核心组件。机载平台下的红外小目标检测面临三重严峻挑战：首先，红外图像本身存在分辨率低、缺乏纹理细节、对比度差的固有限制，其次，从空中俯视的复杂动态背景对小目标检测造成干扰，导致算法虚警率高，最后，无人机载荷对功耗、重量和计算资源的严格限制，要求算法必须在极高的实时性与足够的检测精度之间取得平衡。当前多数基于像素级分割的检测网络，虽在静态基准测试中表现良好，但其庞大的计算量和对高分辨率特征图的需求，使其难以直接部署于机载嵌入式平台进行实时处理。为应对这些挑战，本章提出一种专为无人机平台设计的高效红外小目标检测网络MFF-DCNet。该网络通过协同优化特征提取与融合机制，实现精度与速度的兼顾，核心创新在于：基于深度分离卷积的跨阶段Transformer（Depth-wise Cross-stage Transformer，DCFormer）和多特征聚焦（Multi-Feature Focus，MFF）颈部结构。DCFormer模块通过深度可分离卷积与跨阶段特征融合的结合，在显著降低计算开销的同时，有效增强了主干网络对多尺度上下文信息的建模能力。优化特征提取过程，提升了模型在复杂场景下对小目标的特征判别能力，并且为在边缘设备上的实时部署提供了可能。重新设计的MFF颈部结构通过构建新颖的特征聚合机制，增强了跨尺度特征的整合能力，使模型能够更好地融合不同层级的语义信息和空间细节。这种设计显著提升了模型对多尺度目标的检测性能，特别是在复杂背景下对微小红外目标的精准识别能力。

\xsection{引言}{Introduction}
红外探测系统凭借其被动成像，抗干扰能力强及全天时工作的独特优势，显著提升了无人机的自主感知能力。然而，红外图像普遍存在空间分辨率低、缺乏色彩与丰富纹理细节的局限，导致为高分辨率可见光图像设计的通用深度网络难以直接迁移并提取有效的判别性特征，在典型的无人机应用场景中，地面目标在红外图像中仅占据极少的像素，表现为信噪比极低的弱小目标。同时，复杂的地物背景会引入大量与目标热辐射特征相似的杂波，使得在低信噪比条件下实现精准的“目标-背景”分类变得困难。传统的神经网络，尤其是计算密集的Transformer架构，其高复杂度在算力受限的边缘设备上难以实现实时性能，构成了实际部署的显著瓶颈。因此，在嵌入式设备上实现高精度、高实时性的红外小目标检测是一个亟待解决且具有重要实际价值的研究课题。

针对小目标检测问题，研究者们提出了多种解决方案，如数据增强、背景建模以及聚焦检测等。然而，当这些方法直接应用于红外图像时，其性能往往会因红外成像的物理特性而显著衰减。数据增强策略在可见光图像中能有效增加小目标样本，但在红外图像中可能破坏目标与背景之间的热对比度关系，导致性能提升不稳定且泛化能力有限。背景建模利用目标周围区域提供辅助信息，然而在杂波丰富的红外背景中，过度依赖上下文极易引入干扰噪声，反而模糊了目标本身的特征。聚焦检测类的方法计算成本高，且将大量计算浪费在对广阔背景区域的处理上。

现有的红外小目标检测方法可分为两大技术路线：基于分割的方法与基于检测的方法。基于分割的方法在天空、海面等纯净背景下表现良好。然而，当应用于具有复杂背景的无人机航拍图像时，这类方法的误报率显著升高。红外传感器的远距离成像导致小目标信噪比较低，且目标越小，其像素表现越模糊、不确定性越高，在复杂环境中获取精确的像素级标注也变得更加困难。此外，分割网络通常采用的编码器解码器结构会引入巨大的计算开销，无法在资源受限的嵌入式平台上达到实时处理的要求。 
基于检测的方法专注于直接识别与定位小目标。其中两阶段模型虽能达到较高精度，但常受计算复杂度高的困扰，而单阶段模型则因其高效性在嵌入式系统中日益流行。为提升上下文建模能力，Transformer架构被引入小目标检测网络，以解决捕获长程依赖关系的挑战。其自注意力机制通过计算特征的相关性，使网络能够聚焦于目标区域并捕获更广泛的上下文信息。后续工作中对编码器做出了进一步优化，例如在编码器中引入局部感知块的Local Perception Swin Transformer (LPPSW)，以及融合了全局-局部特征交错模块的双网络结构（Dual network structure with Interweaved Global-Local，DIAG）。这些方法均致力于优化特征提取，以应对复杂航拍图像中的小目标检测难题。虽然这些改进提升了检测精度，但通过复杂自注意力机制带来的性能提升，往往以计算开销的大幅增加为代价。因此，基于Transformer的方法在部署于红外小目标检测系统时，特别是在计算资源有限的边缘计算场景中，仍面临显著局限。

针对上述问题，本章提出 MFF-DCNet，一种基于YOLOv11的高效红外小目标检测网络。通过两项关键创新MFF-DCNet实现了业界领先的效率精度平衡：深度可分离跨阶段Transformer模块（Depth-wise Cross-stage Former，DCFormer）与多特征聚焦颈部结构（Multi-Feature Focus，MFF）。DCFormer通过深度可分离卷积对标准Transformer编码器进行改进，在降低计算复杂度的同时提升了特征提取能力。MFF颈部结构重新定义了原有框架的颈部结构，特征聚合机制跨尺度选择并融合差异化特征，有效抑制了冗余信息。

本文的主要贡献总结如下：
\begin{itemize}
\item 重新设计了整个颈部结构，提出了多特征聚焦模块MFF。这是一种新颖的特征聚合结构，能有效增强不同尺度间特征信息的融合，从而提升模型对多尺度目标（尤其是复杂环境中的红外小目标）的检测能力。

\item 通过引入DCFormer模块增强了主干网络的特征提取能力。该先进的增强模块集成了深度可分离的空间特征提取与跨阶段特征融合，在降低计算成本的同时优化了多尺度上下文建模，提升了复杂场景下的红外小目标检测精度。

\item 在HIT-UAV和DroneVehicle数据集上进行了充分的实验。MFF-DCNet在检测精度（$AP_{50−95}$ 达到 57.4\%，较同类先进方法提升 5.8\%）与处理效率（帧率提升 10\%）上均取得显著进步。同时，该网络在 NVIDIA Jetson Orin NX 边缘计算模块上达到了 39.6 FPS 的稳定实时处理能力，验证了其满足实际机载任务严苛的实时性、可靠性与低功耗要求，具备直接的工程应用价值。
\end{itemize}

\xsection{相关工作}{Related Work}
\xsubsection{面向嵌入式平台的红外小目标检测}{Infrared Small Object Detection for Embedded Platforms}
传统基于建模的方法，如稀疏分解与背景建模，均建立在一个先验假设之上，即小目标可以从结构化背景中被有效分离。与基于深度学习的方法相比，这类方法在面对典型的城市无人机复杂运行环境时，性能严重下降。基于深度学习的红外小目标检测方法主要分为分割方法和检测方法两条技术路线。分割方法将该任务建模为一个正负样本极不平衡的二值语义分割问题，代表性方法可归类为超分辨率、多尺度表征、上下文信息和尺度感知训练等。近期工作LRRNet试图将深度学习与传统的稀疏分解和背景建模相结合。然而，这些分割网络的推理速度通常很慢，即便在标准的消费级GPU上平均帧率也低于10FPS，嵌入式平台的算力通常不足普通桌面级GPU的十分之一，难以支持高复杂度的分割网络实时运行。

嵌入式系统在计算能力、内存和能耗方面面临严格限制。尽管存在众多适用于消费级GPU的高性能算法，但它们往往难以直接部署于无人机等边缘设备上。在边缘设备上部署高性能红外检测算法的主要挑战，在于高计算需求与硬件约束之间的冲突，这推动着研究向轻量化和专用化模型发展。单阶段检测模型因其高效性在嵌入式系统中日益流行，例如MobileNet、ShuffleNet和GhostNet。MobileNet通过使用深度可分离卷积减少了参数量，ShuffleNet使用分组卷积将输入通道划分为更小的组，降低了计算复杂度和参数量，GhostNet引入Ghost模块，通过先使用较少卷积核生成主要特征图，再生成额外的特征图，实现了参数量和计算量的大幅降低。为提高小目标检测精度，这些轻量级主干网络常与多尺度特征学习或超分辨率技术结合使用。例如，SuperYOLO采用对称紧凑的多模态融合技术整合多种数据模态（RGB与红外），并融入超分辨率学习以获取高分辨率特征表示，YOLC利用针对聚类区域的局部尺度模块，但在处理稀疏分布的目标时效果欠佳。

YOLO系列模型在速度与准确性之间取得了出色平衡，是嵌入式平台的理想选择。近期，基于DETR框架的实时检测器（如RT-DETR）被提出。然而，在没有对应领域成熟预训练模型的情况下，DETR极难应用于新领域，因此目前应用最广泛的实时目标检测器仍是YOLO系列。本章提出的MFF-DCNet基于YOLOv11构建，以架构效率为核心设计原则，DCFormer模块通过深度可分离设计减少参数，MFF模块在不依赖昂贵计算成本的编解码器结构的前提下增强了特征判别力。与基于注意力的Transformer方法相比，MFF-DCNet实现了更少的参数量和计算负载，使其更适用于资源受限的嵌入式设备。

\xsubsection{多尺度特征学习方法}{Multiscale Feature Learning Methods}
深度卷积神经网络会生成具有不同空间分辨率的层级化特征图。其中，低层特征蕴含更丰富的细节和定位信息，而高层特征包含更强的语义信息。对于红外小目标检测而言，随着网络深度的增加，小目标的特征表示在最终的特征图中会逐渐减弱。由于红外图像固有的特性（如分辨率低、纹理信息弱），这一问题在红外小目标检测中被进一步放大。为此，一种有效的解决方案是多尺度特征学习，通过整合不同深度的特征来增强对小目标的表征能力。

特征金字塔网络（Feature pyramid Network，FPN）通过构建自顶向下的路径与横向连接，在不同尺寸的特征图上进行预测，并根据目标尺寸将不同尺度的目标分配到对应的金字塔层级。这一多尺度预测的方式被广泛集成于各类目标检测网络中。受到FPN的启发，PANet通过引入双向路径来丰富特征层次，利用精确的定位信号强化深层特征，以更直观方式实现多尺度特征融合的优化。AugFPN则提出残差特征增强与一致性监督，以缩小不同尺度特征间的语义差距。双向特征金字塔网络（Bi-directional Feature Pyramid Network，BiFPN）引入了双向连接，允许信息在网络中同时进行自顶向下和自底向上的流动，确保了对小目标差异化特征的提取，并提升了网络效率。EfficientDet提出了加权的双向FPN，通过引入可学习的权重来评估不同输入特征的重要性，从而实现融合过程中多尺度特征图均衡贡献。空间金字塔池化网络（Spatial Pyramid Pooling，SPP）通过引入空间金字塔池化层，实现从任意尺寸的图像中生成固定长度的特征表示，提升了图像分类与目标检测任务的精度与效率。

传统CNN在处理多尺度目标时面临挑战，视觉Transformer利用层级化的自注意力机制来构建跨尺度的特征表示，而不过度依赖空间降采样，这为红外小目标检测提供了另一种思路。多尺度ViT（Multiscale ViT）将CNN结构中的多尺度特征提取思想与Transformer结合，实现多尺度特征提取。金字塔ViT（Pyramid ViT）使用渐进缩小的金字塔结构来减少大尺寸特征图的计算量，可作为CNN主干网络的替代方案，在目标检测中展现出优越性能。CrossViT 则采用双分支Transformer处理不同尺寸的图像块，生成多尺度图像特征，并通过交叉注意力机制进行特征交互学习。

尽管上述多尺度方法整合了不同层级的特征，但它们通常不加区分地融合所有层次的特征，这会带来计算成本的增加，并可能放大背景噪声，从而导致性能下降。这些局限性凸显了当前方法需要一种更精细、更具选择性的融合策略，以专注于跨尺度中最具信息量的特征。

\xsection{基于多特征聚焦与跨阶段Transformer的检测网络}{Multi-Feature Focus and Cross-Stage Transformer Network}
\xsubsection{模型架构}{Model Architecture}
本节将详细介绍基于多特征聚焦与跨阶段Transformer的目标检测网络MFF-DCNet，其整体框架如图\ref{mmfdcnet-arch}所示。该网络专为红外航拍图像中的小目标检测任务设计，核心包含一个集成了新型DCFormer模块的增强型主干网络和一个设计有MFF模块的创新颈部结构。针对YOLOv11主干网络中C3k2模块存在的计算效率低下以及跨阶段特征融合能力不足的问题，本章设计了DCFormer模块作为其替代。该模块融合了Transformer的设计思想，利用深度可分离卷积作为轻量化的特征混合器，并结合跨阶段残差连接。这一设计通过空间解耦的操作显著降低计算成本，同时通过跨阶段特征重组与高效的长程依赖捕获，增强了模型的上下文建模能力。与此同时，为从根本上改善小目标检测性能，我们设计了一个包含多特征聚焦（Multi-Feature Focus， MFF）模块的全新颈部结构。当前应对多尺度挑战的主流方法是构建特征金字塔来整合不同尺度的特征。然而，对于小目标而言，其特征信息在经过连续的卷积层后会逐渐衰减，导致在最终特征图中保留的有效像素极少。因此，在检测头之前有策略地保留并增强高分辨率特征信息，无疑是提升小目标检测能力的关键。MFF模块正是通过优化特征聚合过程来实现这一目标，它显著增强了网络对于微小目标的检测能力。

\begin{figure}[t]
\centering
\includegraphics[width=\textwidth]{mmfdcnet-arch.png}
\caption{MFF-DCNet网络架构示意图}
\label{mmfdcnet-arch}
\end{figure}

MFF模块通过一个结构化的融合过程来聚合多尺度特征。具体而言，在主干网络完成特征提取后，我们获得特征图P3、P4和P5。这些特征图的分辨率分别为输入图像尺寸的1/8、1/16和1/32。其中，P3层捕获空间细节，P4层在空间细节与语义丰富性之间取得平衡，而P5层则专注于高层语义信息。P4层因其居中的位置，成为双向特征传播的核心枢纽。我们为P4层创建了两个处理分支。一个分支对P4特征图进行3×3卷积以实现下采样，将其与经过SPPF模块和C2PSA模块处理的P5层特征融合，随后通过DCFormer模块处理，输出一个尺寸为20×20×512的特征图。SPPF模块是传统空间金字塔池化（SPP）的优化版本，在保留SPP核心功能的同时提升了计算效率，它通过级联结构串行执行多个相同核尺寸的最大池化操作，C2PSA模块则整合了跨阶段局部连接（Cross Stage Partial）结构与注意力机制，以增强特征表征能力。P4层的另一个分支通过最近邻插值进行上采样，与P3层特征合并，并经由DCFormer模块处理，生成一个80×80×128的特征图。上述操作得到的特征，连同原始的P4层特征，一并送入MFF模块进行进一步的处理。

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{mff-arch.png}
\caption{多特征聚焦模块示意图}
\label{mff-arch}
\end{figure}

\xsubsection{多特征聚焦模块}{Multi-Feature Focus Module}
多特征聚焦模块是特征聚焦颈部结构中的核心组件，负责对来自三个不同尺度的特征进行集成与融合。其详细结构如图\ref{mff-arch}所示，完整的算法流程总结于算法1。具体而言，对于尺寸为$20\times20\times512$的P5层输出特征，首先通过最近邻上采样将其空间尺度扩大一倍至$40 \times 40 \times 512$，随后经过一个$1 \times 1$卷积进行通道调整，得到尺寸为$40 \times 40 \times \mathcal{C}$的特征。对于尺寸为$40 \times 40 \times 256$的P4层输出特征，同样使用$1 \times 1$卷积调整通道数，得到尺寸为$40 \times 40 \times \mathcal{C}$的特征。对于尺寸为$80 \times 80 \times 128$的P3层输出特征，则先通过一个Adown模块进行下采样，再进行通道调整，最终得到尺寸为$40 \times 40 \times \mathcal{C}$的特征，其中，$\mathcal{C}$被设定为P4层特征通道数的一半，在本文中取值为128。此步骤将所有输入特征在空间维度和通道维度上对齐，为后续的特征融合做好准备。



% \scalebox{0.8}{
% \begin{algorithm}[H]
% \caption{Multi-Feature Focus}\label{alg:mff}
% \begin{algorithmic}[1]
% \REQUIRE Input feature maps:
% \STATE $P_5 \in \mathbb{R}^{N \times N \times 4C}$ 
% \STATE $P_4 \in \mathbb{R}^{2N \times 2N \times 2C}$
% \STATE $P_3 \in \mathbb{R}^{4N \times 4N \times C}$ 
% \ENSURE $F_{\text{out}} \in \mathbb{R}^{2N \times 2N \times 2C}$ \quad (fused multiscale features)
% \FOR{$i \in \{3,4,5\}$}
%     \IF{$i = 3$}
%         \STATE $P_i' \gets \text{A}_{\text{down}}(P_i)$
%     \ELSIF{$i = 5$} 
%         \STATE $P_i' \gets \text{Upsample}_{\text{nearest}}(P_i)$
%     \ELSE
%         \STATE $P_i' \gets P_i$
%     \ENDIF

% \STATE $\hat{P}_i \gets \text{Conv}_{1\times1}(P_i')$ 
% \ENDFOR

% \STATE $F_{\text{cat}} \gets [\hat{P}_3, \hat{P}_4, \hat{P}_5]$
% \STATE $F_{\text{fuse}} \gets \text{Conv}_{1\times1}(F_{\text{cat}})$ $\triangleright$ Size: $2N \times 2N \times C$

% \STATE $F_{\text{mp1}} \gets \text{MaxPool}_{5\times5}^{\text{stride=1, pad=2}}(F_{\text{fuse}})$
% \STATE $F_{\text{mp2}} \gets \text{MaxPool}_{5\times5}^{\text{stride=1, pad=2}}(F_{\text{mp1}})$
% \STATE $F_{\text{muti}} \gets [F_{\text{fuse}}, F_{\text{mp1}}, F_{\text{mp2}}]$ $\triangleright$ Size: $2N \times 2N \times 3C$

% \STATE $F_{\text{enhanced}} \gets F_{\text{multi}} \oplus F_{\text{cat}}$
% \STATE $F_{\text{out}} \gets \text{Conv}_{1\times1}(F_{\text{enhanced}})$ $\triangleright$ Size: $2N \times 2N \times 2C$

% \RETURN $F_{\text{out}}$
% \end{algorithmic}
% \end{algorithm}
% }

经过上述处理，所有三个尺度的特征均被对齐到统一的尺度$40 \times 40 \times \mathcal{C}$。随后，这三个尺度相同的特征图被拼接起来，形成初始的融合特征图，其尺寸为$40\times40\times 384$。该拼接后的特征接着通过一个1×1卷积进行处理，以将通道数调整至128，从而得到尺寸为$40 \times40\times128$的特征。此后，使用一个5×5的池化窗口、步长为1并进行边缘填充（以保持输出特征图尺寸）执行两次最大池化操作。将前述三个操作（包括一次1×1卷积和两次最大池化）产生的特征进行拼接。具体而言，这次拼接融合了：经过1×1卷积后的特征（$40\times40\times128$）、第一次最大池化后的特征以及第二次最大池化后的特征，最终得到一个尺寸为$40\times40\times384$的特征。优化后的特征首先与初始拼接阶段产生的融合特征进行相加，随后通过1×1卷积对合并后的特征进行进一步优化，同时保持特征尺度不变，输出最终的融合特征图，其尺寸为$40\times40\times256$。

\xsubsection{基于深度分离卷积的跨阶段Transformer}{Depth-wise Cross-stage transFormer}
YOLOv11的主干网络主要由连续的标准卷积和C3k2模块构成。C3k2模块通过跨阶段局部连接和可变核卷积进行特征整合，其瓶颈结构是负责通道变换和局部上下文聚合的核心。然而，传统的C3k2模块在红外小目标检测中存在关键局限：其串行的卷积结构不可避免地会削弱小目标的判别性特征表示，这一问题在目标缺乏显著纹理、且与复杂背景对比度低的红外图像中尤为突出。

\begin{figure}[ht]
\centering
\includegraphics[width=\textwidth]{dcformer-arch.png}
\caption{DCFormer架构示意图}
\label{dcformer-arch}
\end{figure}

\begin{figure}[ht]
\centering
\includegraphics[width=\textwidth]{convformer.png}
\caption{Convformer架构示意图}
\label{convformer}
\end{figure}

DCFormer模块通过重新设计特征传播路径，利用深度可分离卷积和受Transformer启发的跨阶段特征提取机制，有效应对了上述局限。DCFormer在降低计算成本的同时，增强了对上下文信息的捕获和跨阶段特征提取能力。如图\ref{dcformer-arch}所示，其处理流程始于一个卷积-批归一化-SiLU激活模块（CBS）,所得特征图沿通道维度被均匀分割为两部分,其中一部分通过ConvFormer块（其详细结构见图\ref{convformer}），ConvFormer采用深度可分离卷积作为高效的特征混合器，以替代标准的自注意力机制。另一部分则与ConvFormer的输出沿通道维度进行拼接，从而实现有效的跨阶段信息传播。最后，拼接后的特征再经由另一个CBS模块处理。DCFormer的架构结合了卷积与Transformer思想，优化了特征提取过程，特别是增强对红外小目标的检测能力。值得注意的是，该设计相比原始的C3k2模块，所需的计算成本更低。

DCFormer架构的一个核心组件是ConvFormer，其设计灵感来源于MetaFormer框架，作为主要的特征提取单元。与依赖计算密集型自注意力机制的传统Transformer不同，ConvFormer通过深度可分离卷积实现了一种高效的特征混合策略。该架构用具有线性复杂度的深度可分离卷积替代了具有二次复杂度的注意力操作，使其能够在保持实时处理能力的同时，捕获细微的红外目标特征。ConvFormer的详细结构如图\ref{convformer}所示，它保持了标准Transformer编码器的结构，包含两个主要部分：一是用于空间信息提取的特征混合器（token mixer），二是带有残差连接的多层感知机（Multi-Layer Perceptron，MLP）。在ConvFormer中，特征混合器由深度可分离卷积实现，可以表示为：
\begin{equation}
\label{eq1}
X = DConv(Norm(X)) + X.
\end{equation}

其中，$X$表示输入特征图，$Norm(\cdot)$表示归一化操作，$DConv(\cdot)$表示深度可分离卷积。通过这种设计，ConvFormer能够高效地捕获空间上下文信息，同时保持较低的计算复杂度。随后，通过一个带有StarReLU激活函数的双层MLP进行特征变换：
\begin{equation}
\label{eq2}
X = \sigma(Norm(X)W_1)W_2 + X.
\end{equation}

其中，$W_1$和$W_2$分别表示MLP的权重矩阵，$\sigma(\cdot)$表示StarReLU激活函数。

在ConvFormer中采用深度可分离卷积作为特征混合器，主要基于其在计算效率方面的显著优势，这对于实时红外检测系统至关重要。与标准卷积对所有输入通道执行卷积运算不同，深度可分离卷积将此过程分解为两步：深度卷积和逐点卷积。深度卷积独立处理每个输入通道，而逐点卷积则负责跨通道集成输出。这种分解在保持表征能力的同时，显著减少了参数量和计算成本。假设输入特征图尺寸为$W_i \times H_i \times C_i$，卷积核尺寸为$K_w \times K_h \times C_i$, 输出特征图尺寸为$W_o \times H_o \times C_o$, 对于标准卷积，单个卷积核包含$K_w \times K_h \times C_i$个参数和一个偏置项，共有 $C_o$个卷积核，其参数量和计算量如下：
\begin{equation}
\label{eq3}
\begin{aligned}
Params_{std\_conv} = (K_w \times K_h \times C_i + 1) \times C_o.
\end{aligned}
\end{equation}

\begin{equation}
\label{eq4}
FLOPs_{std\_conv} = K_w \times K_h \times C_i \times W_o \times H_o \times C_o.
\end{equation}

对于深度卷积，单个卷积核的维度为$K_w\times K_h\times 1$，并带有一个偏置项。使用 $C_i$个卷积核，输出特征图维度为$W_o\times H_o\times C_i$，参数量和计算量如下：
\begin{equation}
\label{eq5}
Params_{depth\_conv} = (K_w \times K_h \times 1 + 1) \times C_i.
\end{equation}
\begin{equation}
\label{eq6}
FLOPs_{depth\_conv} = K_w \times K_h \times W_o \times H_o \times C_i.
\end{equation}

对于逐点卷积，单个卷积核的维度为$1\times 1\times C_i$，并带有一个偏置项，使用$C_o$个卷积核，参数量和计算量如下：
\begin{equation}
\label{eq7}
Params_{point\_conv} = (1 \times 1 \times C_i + 1) \times C_o.
\end{equation}
\begin{equation}
\label{eq8}
FLOPs_{point\_conv} = C_i \times W_o \times H_o \times C_o.
\end{equation}

对于深度可分离卷积，总参数量和总计算量为：
\begin{equation}
\label{eq9}
Params_{Dconv} = (K_w \times K_h + 1) \times C_i + (C_i + 1) \times C_o.
\end{equation}
\begin{equation}
\label{eq10}
FLOPs_{Dconv} = W_o \times H_o \times C_i \times (K_w \times K_h + C_o).
\end{equation}

假设$K_w=K_h=K$，通过将传统卷积替换为深度可分离卷积，理论计算量可降低至标准卷积的$\frac{1}{C_o} + \frac{1}{K^2}$，图\ref{dc-sc}直观对比了标准卷积与深度卷积的处理过程。

\begin{figure}[!t]
\centering

\subfloat[]{\includegraphics[width=2.5in]{dc-sc-a.png}%
\label{fig_first_case}}
\hfil
\subfloat[]{\includegraphics[width=2.5in]{dc-sc-b.png}%
\label{fig_second_case}}
\caption{(a) Standard convolution. (b) Depth-wise separable convolution.}
\label{dc-sc}
\end{figure}

\xsection{实验结果与分析}{Experimental Results and Analysis}
\xsubsection{数据集与评价指标}{Datasets and Evaluation Metrics}



